# -*- coding: utf-8 -*-
"""M22AIE211_DLOps_ClassAssignment_2_Q_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Az8a8-j9DHYmlzmims_LqxT5BNBGKxnX

# My Roll Number is M22AIE211, 211 MOD = 1. Hence I will SVHN dataset
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.models import resnet50
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.RandomRotation(degrees=15), #Added Random rotations in version2
    transforms.RandomHorizontalFlip(), #Added Random horizontal flips in version2
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Loaded SVHN dataset
dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True) # Increased the batch size in version2

# Loading pre-trained ResNet50 model
model = resnet50(pretrained=True)

# Freezing convolutional layers
for param in model.parameters():
    param.requires_grad = False

f = model.fc.in_features

# Added Dropout in version 2
model.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(f, 10)
)

model = model.to(device)

criterion = nn.CrossEntropyLoss()

# optimizers
optimizers = {
    'Adam': optim.Adam(model.parameters(), lr=0.001),
    'Adagrad': optim.Adagrad(model.parameters(), lr=0.01),
    'RMSprop': optim.RMSprop(model.parameters(), lr=0.001),
}

def train_model(optimizer, num_epochs=5):
    train_loss_history = []
    train_acc_history = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        epoch_loss = running_loss / len(dataloader)
        epoch_acc = 100. * correct / total

        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')

        train_loss_history.append(epoch_loss)
        train_acc_history.append(epoch_acc)

    return train_loss_history, train_acc_history

# Added model Evaluation method in version2
def evaluate_model(model, dataloader):
    model.eval()
    correct = 0
    total = 0
    pred_list = []
    label_list = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
            pred_list.extend(predicted.cpu().numpy())
            label_list.extend(labels.cpu().numpy())

    precision = precision_score(label_list, pred_list, average='macro')
    recall = recall_score(label_list, pred_list, average='macro')

    accuracy = 100. * correct / total
    print('Accuracy: {:.2f}%, Precision: {:.2f}, Recall: {:.2f}'.format(accuracy, precision, recall))
# Training with all 3 Optimizers
for optimizer_name, optimizer in optimizers.items():
    print(f'Training with {optimizer_name} optimizer:')
    train_loss, train_acc = train_model(optimizer)

    plt.plot(train_loss, label='Train Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title(f'Training Loss with {optimizer_name} optimizer')
    plt.legend()
    plt.show()

    plt.plot(train_acc, label='Train Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(f'Training Accuracy with {optimizer_name} optimizer')
    plt.legend()
    plt.show()